#!/usr/bin/env python3
import argparse
import json
import signal
import string
import subprocess
import sys
from contextlib import ExitStack
from dataclasses import dataclass, field
from pathlib import Path
from urllib.parse import urlparse


# Credit: https://stackoverflow.com/a/1094933
def _sizeof_fmt(num: float, suffix: str = "B") -> str:
    for unit in ("", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"):
        if abs(num) < 1024.0:
            return f"{num:3.1f} {unit}{suffix}"
        num /= 1024.0
    return f"{num:.1f} Yi{suffix}"


def _run_dockerized_ogr2ogr(database_url, directory: Path, path: Path, options: list):
    assert directory.is_absolute()
    assert path.is_absolute()

    # Make ogr2ogr access database tunnel connection open on the host
    # https://stackoverflow.com/a/43541732
    urlobj = urlparse(database_url)
    database_url_from_container = urlobj._replace(
        netloc=f"{urlobj.username}:{urlobj.password}@host.docker.internal:{urlobj.port}"
    ).geturl()

    command = [
        "docker",
        "compose",
        "-f",
        "docker-compose.yml",
        "--profile",
        "gdal",
        "run",
        "--rm",  # Do not leave dead containers
        "-v",
        f"{directory}:/home/data",
        "gdal",
        "ogr2ogr",
        # Setup connection to the PostgreSQL database
        # See specific PostgreSQL options here:
        # https://gdal.org/drivers/vector/pg.html
        "-f",
        "PostgreSQL",
        f"PG:{database_url_from_container}",
        *options,
        str(Path("/home/data") / path.relative_to(directory)),
    ]

    return subprocess.run(command)


@dataclass
class CustomIndex:
    name: str
    create_statement: str


@dataclass
class Config:
    tables: list[str]
    custom_indexes: list[CustomIndex] = field(default_factory=list)


def main(config: Config, transport_dir: Path, target: str, yes: bool) -> int:
    if not transport_dir.exists():
        print(f"ERROR: directory {transport_dir} does not exist", file=sys.stderr)
        return 1

    geopackage_paths = [
        path
        for path in transport_dir.glob("*/BDTOPO/1_DONNEES_LIVRAISON_*/*/TRANSPORT/*")
        if path.stem in config.tables
    ]

    if not geopackage_paths:
        print("ERROR: no geopackages found", file=sys.stderr)
        return 1

    # Improve disk usage by importing smallest packages first.
    # Reason: initial TRUNCATE only runs *after* importing the 1st package.
    geopackage_paths = sorted(geopackage_paths, key=lambda p: p.stat().st_size)

    with ExitStack() as exit_stack:
        if target.startswith(("postgresql://", "postgres://")):
            hostname = urlparse(target).hostname

            if hostname not in ("localhost", "127.0.0.1"):
                print(
                    f"ERROR: database URL target must be on localhost, received: {hostname}"
                )

            database_url = target
        else:
            app = target

            print(f"===> Opening DB tunnel to app {app}...")

            tunnel_proc = exit_stack.enter_context(
                subprocess.Popen(
                    ["./tools/scalingodbtunnel", app, "--host-url"],
                    stdout=subprocess.PIPE,
                )
            )

            def _close_tunnel():
                print("---> Stopping tunnel...")
                tunnel_proc.send_signal(signal.SIGINT)
                tunnel_proc.wait()

            exit_stack.callback(_close_tunnel)

            database_url = (
                tunnel_proc.stdout.readline()
                .decode()
                .strip()  # Remove any final newline
            )

            if not database_url:
                print(
                    "ERROR: failed to open DB tunnel, see output above",
                    file=sys.stderr,
                )
                return 1

            print("---> Tunnel open.")

        # ogr2ogr only seems to support postgresql://, especially when query parameters
        # are provided, such as '?sslmode=prefer' by Scalingo.
        database_url = database_url.replace("postgres://", "postgresql://")

        print("===> Will import into")
        print(database_url)

        if not yes and input("------> Proceed? (y/N) ") != "y":
            return 1

        print("===> Importing BD TOPO content...")
        tables_seen = set()

        try:
            for path in geopackage_paths:
                tablename = path.stem  # e.g. voie_nommee

                pretty_size = _sizeof_fmt(path.stat().st_size)
                print(f"------> Import into {tablename}: {path} ({pretty_size})")

                options = [
                    # See general ogr2ogr options here:
                    # https://gdal.org/programs/ogr2ogr.html
                    "-progress",
                    # Define the table name on initial import
                    "-nln",
                    tablename,
                    # Append on subsequent calls
                    "-append",
                    # Enable slightly faster ingestion
                    # https://gdal.org/drivers/vector/pg.html#config-PG_USE_COPY
                    "--config",
                    "PG_USE_COPY",
                    "YES",
                ]

                if tablename not in tables_seen:
                    options.extend(
                        [
                            # Remove existing tuples before importing (saves disk space
                            # at the cost of some unavailability during execution)
                            # https://gis.stackexchange.com/a/357040
                            # This should only run once per table so that all packages
                            # are effectively appended.
                            "--config",
                            "OGR_TRUNCATE",
                            "YES",
                        ]
                    )

                    tables_seen.add(tablename)

                result = _run_dockerized_ogr2ogr(
                    database_url,
                    directory=transport_dir,
                    path=path,
                    options=options,
                )

                if result.returncode:
                    print(
                        "ERROR: ogr2ogr command failed, see output above",
                        file=sys.stderr,
                    )
                    return 1

            print("------> Import successful!")

            if config.custom_indexes:
                print("===> Configuring custom indexes...")

                statements = []

                for custom_index in config.custom_indexes:
                    # Drop indexes in case their definition has changed.
                    drop_stmt = f"DROP INDEX IF EXISTS {custom_index.name};"

                    create_stmt = string.Template(
                        custom_index.create_statement
                    ).substitute(name=custom_index.name)

                    statements += [drop_stmt, create_stmt]

                for analyze_stmt in statements:
                    analyze_stmt += "" if analyze_stmt.endswith(";") else ";"

                    print("------>", analyze_stmt)

                    result = subprocess.run(
                        ["psql", database_url, "-c", analyze_stmt],
                        stdout=subprocess.DEVNULL,
                    )
                    result.check_returncode()

                print("------> Indexes successfully configured!")

            # Update table statistics so that COUNT, indexes, etc work immediately.
            # NOTE: VACUUM will run automatically later thanks to Scalingo's autovacuum.
            print("===> Running ANALYZE...")
            # TODO: need VACUUM too
            analyze_stmt = f"ANALYZE VERBOSE {', '.join(tables_seen)};"
            print("------>", analyze_stmt)
            result = subprocess.run(["psql", database_url, "-c", analyze_stmt])
            result.check_returncode()
            print("------> ANALYZE ran successfully!")
        except KeyboardInterrupt:
            # ogr2ogr already manages most of the cleanup for us, nothing to do.
            return 2

    return 0


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "transport_dir",
        type=Path,
        help="Path to directory of BD TOPO Transport Theme data",
    )
    parser.add_argument(
        "target", help="Name of Scalingo app, or a PostgreSQL database URL"
    )
    parser.add_argument(
        "--prod", action="store_true", help="Required if targetting 'dialog' app"
    )
    parser.add_argument("-y", "--yes", action="store_true", help="Accept all prompts")
    parser.add_argument(
        "-c",
        "--config",
        type=Path,
        default=Path(__file__).parent / "bdtopo_update.config.json",
        help="Path to config file. Default: ./bdtopo_update.config.json",
    )
    args = parser.parse_args()

    if args.target == "dialog" and not args.prod:
        print(
            "ERROR: please pass --prod when targetting the production environment",
            file=sys.stderr,
        )
        sys.exit(1)

    configdata = json.loads(args.config.read_text())

    config = Config(
        tables=configdata["tables"],
        custom_indexes=[
            CustomIndex(**fields) for fields in configdata.get("custom_indexes", [])
        ],
    )

    # Relative paths are OK but ogr2ogr volume will require an absolute path.
    transport_dir = args.transport_dir.absolute()

    sys.exit(
        main(
            config,
            transport_dir=transport_dir,
            target=args.target,
            yes=args.yes,
        )
    )
