#!/usr/bin/env python3
import argparse
import json
import re
import signal
import string
import subprocess
import sys
from contextlib import ExitStack
from dataclasses import dataclass, field
from pathlib import Path
from urllib.parse import urlparse


# Credit: https://stackoverflow.com/a/1094933
def _sizeof_fmt(num: float, suffix: str = "B") -> str:
    for unit in ("", "Ki", "Mi", "Gi", "Ti", "Pi", "Ei", "Zi"):
        if abs(num) < 1024.0:
            return f"{num:3.1f} {unit}{suffix}"
        num /= 1024.0
    return f"{num:.1f} Yi{suffix}"


def _run_dockerized_ogr2ogr(database_url, directory: Path, path: Path, options: list):
    assert directory.is_absolute()
    assert path.is_absolute()

    # Make ogr2ogr access database tunnel connection open on the host
    # https://stackoverflow.com/a/43541732
    urlobj = urlparse(database_url)
    database_url_from_container = urlobj._replace(
        netloc=f"{urlobj.username}:{urlobj.password}@host.docker.internal:{urlobj.port}"
    ).geturl()

    command = [
        "docker",
        "compose",
        "-f",
        "docker-compose.yml",
        "--profile",
        "gdal",
        "run",
        "--rm",  # Do not leave dead containers
        "-v",
        f"{directory}:/home/data",
        "gdal",
        "ogr2ogr",
        # Setup connection to the PostgreSQL database
        # See specific PostgreSQL options here:
        # https://gdal.org/drivers/vector/pg.html
        "-f",
        "PostgreSQL",
        f"PG:{database_url_from_container}",
        *options,
        str(Path("/home/data") / path.relative_to(directory)),
    ]

    return subprocess.run(command)


@dataclass
class Config:
    tables: list[str]


def main(config: Config, directory: Path, url: str | None, yes: bool) -> int:
    if not directory.exists():
        print(f"ERROR: directory {directory} does not exist", file=sys.stderr)
        return 1

    search_pattern = "*/BDTOPO/1_DONNEES_LIVRAISON_*/*/TRANSPORT/*"

    geopackage_paths = [
        path for path in directory.glob(search_pattern) if path.stem in config.tables
    ]

    if not geopackage_paths:
        print(
            f"ERROR: no geopackages found at {directory} "
            f"using pattern {search_pattern!r}",
            file=sys.stderr,
        )
        return 1

    # Improve pg disk usage by importing smallest packages first.
    # Reason: ogr2ogr runs TRUNCATE *after* importing the 1st package.
    geopackage_paths = sorted(geopackage_paths, key=lambda p: p.stat().st_size)

    with ExitStack() as exit_stack:
        if url is not None:
            urlobj = urlparse(url)

            if urlobj.scheme not in ("postgres", "postgresql"):
                print(
                    f"ERROR: invalid database URL: {url}: "
                    f"unexpected scheme: {urlobj.scheme} "
                    "(expected postgres:// or postgresql://)"
                )
                return 1

            if urlobj.hostname not in ("localhost", "127.0.0.1"):
                print(
                    "ERROR: expected url to be on localhost, "
                    f"received: {urlobj.hostname}"
                )
                return 1

            database_url = url
        else:
            app = "dialog-bdtopo"

            print(f"===> Opening DB tunnel to {app}...")

            tunnel_proc = exit_stack.enter_context(
                subprocess.Popen(
                    ["./tools/scalingodbtunnel", app, "--host-url"],
                    stdout=subprocess.PIPE,
                )
            )

            def _close_tunnel():
                print("---> Stopping tunnel...")
                tunnel_proc.send_signal(signal.SIGINT)
                tunnel_proc.wait()

            exit_stack.callback(_close_tunnel)

            database_url = (
                tunnel_proc.stdout.readline()
                .decode()
                .strip()  # Remove any final newline
            )

            if not database_url:
                print(
                    "ERROR: failed to open DB tunnel, see output above",
                    file=sys.stderr,
                )
                return 1

            print("---> Tunnel open.")

        # ogr2ogr only seems to support postgresql://, especially when query parameters
        # are provided, such as '?sslmode=prefer' by Scalingo.
        database_url = database_url.replace("postgres://", "postgresql://")

        print("===> Will import into:")
        print(database_url)

        if not yes and input("------> Proceed? (y/N) ") != "y":
            return 1

        print("===> Importing BD TOPO content...")
        tables_seen = set()

        try:
            for path in geopackage_paths:
                tablename = path.stem  # e.g. voie_nommee

                pretty_size = _sizeof_fmt(path.stat().st_size)
                print(f"------> Import into {tablename}: {path} ({pretty_size})")

                options = [
                    # See general ogr2ogr options here:
                    # https://gdal.org/programs/ogr2ogr.html
                    "-progress",
                    # Define the table name on initial import
                    "-nln",
                    tablename,
                    # Append on subsequent calls
                    "-append",
                    # Enable slightly faster ingestion
                    # https://gdal.org/drivers/vector/pg.html#config-PG_USE_COPY
                    "--config",
                    "PG_USE_COPY",
                    "YES",
                ]

                if tablename not in tables_seen:
                    options.extend(
                        [
                            # Remove existing tuples before importing (saves disk space
                            # at the cost of some unavailability during execution)
                            # https://gis.stackexchange.com/a/357040
                            # This should only run once per table so that all packages
                            # are effectively appended.
                            "--config",
                            "OGR_TRUNCATE",
                            "YES",
                        ]
                    )

                    tables_seen.add(tablename)

                result = _run_dockerized_ogr2ogr(
                    database_url,
                    directory=directory,
                    path=path,
                    options=options,
                )

                if result.returncode:
                    print(
                        "ERROR: ogr2ogr command failed, see output above",
                        file=sys.stderr,
                    )
                    return 1

            print("------> Import successful!")

            # Clear up dead tuples and update table statistics so that the
            # tables can be queried immediately.
            print("===> Running VACUUM ANALYZE...")
            analyze_stmt = f"VACUUM (ANALYZE, VERBOSE) {', '.join(tables_seen)};"
            print("------>", analyze_stmt)
            result = subprocess.run(
                [
                    "psql",
                    database_url,
                    # Avoid 'No space left on device' error when available RAM is short
                    "-c",
                    "SET max_parallel_maintenance_workers = 0;",
                    "-c",
                    analyze_stmt,
                ]
            )
            result.check_returncode()
            print("------> VACUUM ANALYZE ran successfully!")
        except KeyboardInterrupt:
            # ogr2ogr already manages most of the cleanup for us, nothing to do.
            return 2
        else:
            print("===> Done")

    return 0


def _path_check_exists(value: str) -> Path:
    path = Path(value)

    if not path.exists():
        raise argparse.ArgumentTypeError(f"file or directory not found: {value}")

    return path


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "directory",
        type=_path_check_exists,
        help="Path to directory containing BD TOPO data",
    )
    parser.add_argument(
        "--prod", action="store_true", help="Confirm deployment to 'dialog-bdtopo' app"
    )
    parser.add_argument(
        "--url",
        help="Deploy to a PostgreSQL database identified by this database URL",
        default=None,
    )
    parser.add_argument("-y", "--yes", action="store_true", help="Accept all prompts")
    parser.add_argument(
        "-c",
        "--config",
        type=_path_check_exists,
        default=Path(__file__).parent / "bdtopo_update.config.json",
        help="Path to config file. Default: ./bdtopo_update.config.json",
    )
    args = parser.parse_args()

    if args.url is None and not args.prod:
        print(
            "ERROR: please pass --prod to deploy to 'dialog-bdtopo' environment, "
            "or --url to target a specific PostgreSQL database",
            file=sys.stderr,
        )
        sys.exit(1)

    configdata = json.loads(args.config.read_text())

    config = Config(
        tables=configdata["tables"],
    )

    # Relative paths are OK but ogr2ogr volume will require an absolute path.
    directory = args.directory.absolute()

    sys.exit(
        main(
            config,
            directory=directory,
            url=args.url,
            yes=args.yes,
        )
    )
